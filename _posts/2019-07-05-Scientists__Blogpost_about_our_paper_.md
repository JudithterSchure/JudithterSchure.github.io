---
layout: post
title: "[Scientists] Blogpost about our paper!"
date: 2019-07-05
description: "The blog The Replication Network - Furthering the Practice of Replication in Economics published a summary of our Accumulation Bias paper by co-founder Professor Bob Reed of the University of Canterbury, New Zealand. You can read it here.It is a summary of cited sentences and provides a very nice and short overview of the most important points of the paper. I couldn't have done it better myself!"
tags: []
categories: ["Scientists"]
thumbnail: /assets/img/posts/Scientists__Blogpost_about_our_paper_-thumbnail.png
---
![](/assets/img/posts/Scientists__Blogpost_about_our_paper_-0.png)

The blog The Replication Network - Furthering the Practice of Replication in Economics published a summary of our Accumulation Bias paper by co-founder Professor Bob Reed of the University of Canterbury, New Zealand. You can read it [here](https://replicationnetwork.com/2019/07/05/to-your-list-of-biases-in-meta-analyses-add-this-one-accumulation-bias/).

It is a summary of cited sentences and provides a very nice and short overview of the most important points of the paper. I couldn't have done it better myself:

“Studies accumulate over time and meta-analyses are mainly retrospective. These two characteristics introduce dependencies between the analysis time, at which a series of studies is up for meta-analysis, and results within the series.”

“Dependencies introduce bias — Accumulation Bias — and invalidate the sampling distribution assumed for p-value tests, thus inflating type-I errors.”

“…by using p-value methods, conventional meta-analysis implicitly assumes that promising initial results are just as likely to develop into (large) series of studies as their disappointing counterparts. Conclusive studies should just as likely trigger meta-analyses as inconclusive ones. And so the use of p-value tests suggests that results of earlier studies should be unknown when planning new studies as well as when planning meta-analyses.”

“Such assumptions are unrealistic… ignoring these assumptions invalidates conventional p-value tests and inflates type-I errors.”

“… we argue throughout the paper that any efficient scientific process will introduce some form of Accumulation Bias and that the exact process can never be fully known.”

“A likelihood ratio approach to testing solves this problem … Firstly, it agrees with a form of the stopping rule principle … Secondly, it agrees with the Prequential principle … Thirdly, it allows for a betting interpretation …: reinvesting profits from one study into the next and cashing out at any time.”

“This leads to two main conclusions. First, Accumulation Bias is inevitable, and even if it can be approximated and accounted for, no valid p-value tests can be constructed. Second, tests based on likelihood ratios withstand Accumulation Bias: they provide bounds on error probabilities that remain valid despite the bias.”

Fri, 05 July
