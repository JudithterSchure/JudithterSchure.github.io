<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://judithterschure.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://judithterschure.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-10-27T17:42:55+00:00</updated><id>https://judithterschure.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">[Scientists] OSCAward for ALL-IN-META-BCG-CORONA</title><link href="https://judithterschure.github.io/blog/Scientists__OSCAward_for_ALL-IN-META-BCG-CORONA-thumbnail" rel="alternate" type="text/html" title="[Scientists] OSCAward for ALL-IN-META-BCG-CORONA"/><published>2025-06-24T00:00:00+00:00</published><updated>2025-06-24T00:00:00+00:00</updated><id>https://judithterschure.github.io/blog/Scientists__OSCAward_for_ALL-IN-META-BCG-CORONA-thumbnail</id><content type="html" xml:base="https://judithterschure.github.io/blog/Scientists__OSCAward_for_ALL-IN-META-BCG-CORONA-thumbnail"><![CDATA[<p><img src="/assets/img/posts/Scientists__OSCAward_for_ALL-IN-META-BCG-CORONA-0.jpg" alt=""/></p> <p>Here I share the story of the project that motivated me to nominate it, see the nomination text below. Lessons learned in terms of the unique features of the ALL-IN approach appeared in an updated (V2) version of the ALL-IN paper:</p> <p>ter Schure J and Grünwald P. ALL-IN meta-analysis: breathing life into living systematic reviews and prospective meta-analyses [version 2; peer review: 1 approved, 2 approved with reservations]. F1000Research 2025, 11:549 (<a href="https://doi.org/10.12688/f1000research.74223.2">https://doi.org/10.12688/f1000research.74223.2</a>)</p> <h2 id="oscaward-nomination">OSCAward nomination</h2> <h3 id="3-project-information">3. Project Information</h3> <h4 id="a-project-title">a. Project title</h4> <p>ALL-IN-META-BCG-CORONA</p> <h4 id="b-project-category">b. Project category</h4> <p>Open access/ Open data/ Open materials/ Open software</p> <h3 id="4-project-description">4. Project Description</h3> <h4 id="a-objective-of-the-project">a. Objective of the project</h4> <p>Launched in the spring of 2020, this project’s first objective was to reach a conclusion on a COVID-19 related scientific question as soon as possible. When the scientific question became less relevant, its subsequent objective was to make all details available of a collaborative approach to clinical trial research that would exemplify (1) open science principles, (2) reducing research waste, (3) living materials that are fully citable and findable by citations, (4) rewarding all roles in the process by citations, (5) show-case statistical methods that facilitate collaboration like none other can, and (6) reach the audience that would like to repeat such a project (with a 2025 update to the ALL-IN methodological paper).</p> <h4 id="b-project-description">b. Project description</h4> <p>ALL-IN-META-BCG-CORONA is a prospective living meta-analysis of clinical trials that studied the protection of the BCG vaccine (originally developed to protect against tuberculosis) against COVID-19 infections and hospitalizations.</p> <p>The ALL-IN approach to prospective meta-analysis promotes many open science principles. Hence the nomination of this project as the first application of the approach.</p> <p>A second rationale for nomination is that this successful project looks like a failure: (1) Slow data sharing: even with everything (statistical design and dashboard infrastructure) in place to do efficient science, the interim results still could not affect the value/research waste of new trials. (2) A paper stuck in the preprint stage that (3) is hardly cited within the BCG research field, because (quote by a clinical researcher) ‘citing preprints is frowned upon in clinical research’, even when reviewed by 22 authors, in line with EQUATOR Network research reporting checklist, and openly available with a complete Replication Package. (4) A mostly failed attempt to use the underlying scientific work to give credit, make scientific evaluation findable, and highlight authors module-by-module.</p> <p>The reason for giving this project more publicity is that even with knowledge of how it turned out, if I could go back in time, I would do everything exactly the same. It is still the best way to adhere to Open Science principles that I know about. (Although it would have been better if I already had the funding for legal-statistical research into sharing data without involvement of legal departments.) It started with excited collaborators, but was a lonely process after everyone lost interest in the scientific question (after rollout of COVID-19 specific vaccines (Pfizer/BioNtech, Moderna etc.)), and evolving scientific research pointed to futility.</p> <h3 id="5-open-science-principles-impact-and-sustainability">5. Open Science Principles, Impact, and Sustainability</h3> <h4 id="a-alignment-with-open-science-values">a. Alignment with open science values</h4> <p>Collaboration in a prospective meta-analysis avoids research integrity problems like filedrawering, outcome switching, incompatible outcome measures, unnecessary heterogeneity, small sample size, unnecessary new trials, and unnecessary delays in scientific conclusions if a living analysis is used. The latter is facilitated by the ALL-IN statistical approach that allows for bottom-up collaboration, in contrast to other statistical approaches to sequential analysis that require outside control over stopping the participating studies.</p> <h4 id="b-potential-to-improve-science-or-benefit-society">b. Potential to improve science or benefit society</h4> <p>The methodology reached the interest of the EU-RESPONSE consortium that added an ALL-IN work package into to their Horizon pandemic preparedness grant, based on the complete example of the methodology in the ALL-IN-META-BCG-CORONA project.</p> <p>The experience with data transfer agreements inspired a research proposal that will study how to do such ALL-IN prospective meta-analysis based on sharing summary statistics alone (in a federated fashion) such that data sharing agreements might not be needed. This work package is part of a larger research proposal to adapt the ALL-IN methods developed for COVID-19 trials to trials in oncology. The proposal was evaluated as ‘fundable’ in the ZonMw Open Competition of 2023 and reached the interview round in 2024, and was resubmitted in the ZonMw Open Competition of 2025.</p> <h4 id="c-potential-to-foster-diversity-and-inclusion">c. Potential to foster diversity and inclusion</h4> <p>Some countries have more difficulty recruiting participants in clinical trials than others. Hungary, for example (HU in the collaboration), experienced much more vaccine hesitancy than other countries and had low participation in vaccine trials because of it (and hence small sample size). Not only did this collaboration save this data from the filedrawer, it also put the research team on equal footing with the others due to the bottom-up nature of the statistical approach that is agnostic to sample size.</p> <p>The ResearchEquals platform was used for the replication package, not only to make the project reproducible and replicable but to achieve three additional goals: First, to give credit to other important work of those not involved in the ALL-IN-META-BCG-CORONA project as authors, but indispensable for the trial design and data collection. Second, to make standalone modules findable through citations that have their own scientific value. And third to highlight the different authorships of the various modules.</p> <h4 id="d-sustainability">d. Sustainability</h4> <p>ResearchEquals might not be a sustainable platform (relatively new), so there was a trade-off with the three additional goals mentioned above. Software is available in an R package on CRAN, within the EU-RESPONSE consortium a grant is available to hire a software specialist to create sustainable software.</p> <h3 id="6-public-summary-of-the-project">6. Public Summary of the Project</h3> <h4 id="a-title">a. Title</h4> <p>ALL-IN-META-BCG-CORONA: open science methods showcased on ResearchEquals</p> <h4 id="b-public-summary">b. Public Summary</h4> <p>ALL-IN-META-BCG-CORONA is a prospective living meta-analysis of clinical trials that studied the protection of the BCG vaccine (originally developed to protect against tuberculosis) against COVID-19 infections and hospitalizations. The statistical methods in the project add to other methods for prospective meta-analysis by their bottom-up nature that puts all participating clinical trial teams on an equal footing in the collaboration. The resulting paper is openly available and has a replication package that not only inspires similar projects and allows for reuse of documentation, but also aimed for goals to make standalone supplementary material findable through citations, highlight authorship and give credit to authors that for logistical reasons could not author the publication. While the project failed those latter goals because platforms like Google Scholar, PubMed, Scopus stopped showing/never showed ResearchEquals citations, the ideas behind the attempt are worth sharing within the open science community.</p> <h3 id="7-output-related-to-the-project">7. Output related to the project</h3> <p>MedRxiv preprint ALL-IN-META-BCG-CORONA</p> <p>Bacillus Calmette-Guérin vaccine to reduce COVID-19 infections and hospitalisations in healthcare workers – a living systematic review and prospective ALL-IN meta-analysis of individual participant data from randomised controlled trials</p> <p>J.A. (Judith) ter Schure, Alexander Ly, Lisa Belin, Christine S. Benn, Marc J.M. Bonten, Jeffrey D. Cirillo, Johanna A.A. Damen, Inês Fronteira, Kelly D. Hendriks, Ana Paula Junqueira-Kipnis, André Kipnis, Odile Launay, Jose Euberto Mendez-Reyes, Judit Moldvay, Mihai G. Netea, Sebastian Nielsen, Caryn M. Upton, Gerben van den Hoogen, Jesper M. Weehuizen, Peter D. Grünwald, C.H. (Henri) van Werkhoven medRxiv 2022.12.15.22283474; doi: <a href="https://doi.org/10.1101/2022.12.15.22283474">https://doi.org/10.1101/2022.12.15.22283474</a></p> <p>ResearchEquals replication package ALL-IN-META-BCG-CORONA</p> <p><a href="https://doi.org/10.53962/kyep-h9">https://doi.org/10.53962/kyep-h9</a></p> <h3 id="8-references">8. References</h3> <p>Blog post detailing the excitement of doing prospective meta-analys in a live dashboard and initiating the ALL-IN-META-BCG-CORONA project: <a href="https://significanthelp.nl/Personal-COVID-19-trial-dashboard">https://significanthelp.nl/Personal-COVID-19-trial-dashboard</a></p> <p>Media coverage of the innovative statistical approach: <a href="https://significanthelp.nl/General-Interview-in-Het-Parool-en-New-Scientist">https://significanthelp.nl/General-Interview-in-Het-Parool-en-New-Scientist</a></p> <p>Blog post detailing the failure of fast data sharing, and how the research effort could have been more valuable without data transfer agreements: <a href="https://significanthelp.nl/Blog/Scientists-Avoidable-research-waste-caused-by-data-transfer-agreements">https://significanthelp.nl/Blog/Scientists-Avoidable-research-waste-caused-by-data-transfer-agreements</a></p> <p>Blog post detailing the failure of using citations of underlying scientific effort to give credit, make modules findable, and highlight authorship: <a href="https://significanthelp.nl/Blog/Scientists-What-I-tried-to-achieve-with-a-ResearchEquals-collection">https://significanthelp.nl/Blog/Scientists-What-I-tried-to-achieve-with-a-ResearchEquals-collection</a></p> <p>Journal publication about the benefits of the ALL-IN statistical approach for bottom-up collaboration updated into a V2 with the ALL-IN-META-BCG-CORONA results:</p> <p>ter Schure J and Grünwald P. ALL-IN meta-analysis: breathing life into living systematic reviews and prospective meta-analyses [version 2; peer review: 1 approved, 2 approved with reservations]. F1000Research 2025, 11:549 (<a href="https://doi.org/10.12688/f1000research.74223.2">https://doi.org/10.12688/f1000research.74223.2</a>)</p>]]></content><author><name></name></author><category term="Scientists"/><summary type="html"><![CDATA[Here I share the story of the project that motivated me to nominate it, see the nomination text below. Lessons learned in terms of the unique features of the ALL-IN approach appeared in an updated (V2) version of the ALL-IN paper: ter Schure J and Grünwald P. ALL-IN meta-analysis: breathing li...]]></summary></entry><entry><title type="html">[Scientists] What I tried to achieve with a ResearchEquals collection</title><link href="https://judithterschure.github.io/blog/Scientists__What_I_tried_to_achieve_with_a_ResearchEquals_collection" rel="alternate" type="text/html" title="[Scientists] What I tried to achieve with a ResearchEquals collection"/><published>2025-05-12T00:00:00+00:00</published><updated>2025-05-12T00:00:00+00:00</updated><id>https://judithterschure.github.io/blog/Scientists__What_I_tried_to_achieve_with_a_ResearchEquals_collection</id><content type="html" xml:base="https://judithterschure.github.io/blog/Scientists__What_I_tried_to_achieve_with_a_ResearchEquals_collection"><![CDATA[<p><img src="/assets/img/posts/Scientists__What_I_tried_to_achieve_with_a_ResearchEquals_collection-0.png" alt=""/> <strong><em>How I did the best I could and spent a large amount of time, still gave up before fully completing it, am happy I tried it, happy I gave up, and happy with the result.</em></strong></p> <p>ResearchEquals is a research publishing platform that is used by open science enthusiasts like myself. This blog post is about my use of the platform for the Replication Package ALL-IN-META-BCG-CORONA.</p> <p>You can find it here: <a href="https://www.researchequals.com/collections/kyep-h9">Replication Package ALL-IN-META-BCG-CORONA</a></p> <p>This collection transparently details a collaboration with fourteen clinical researchers representing seven clinical trials (NL, SA, US, DK, HU, BR, AF) – in a prospective meta-analysis with three senior researchers in a steering committee, two statisticians, and an external risk-of-bias team.</p> <p>The ResearchEquals collection tries to make all supplementary material of the collaboration available for anyone that wants to reproduce our work or start a similar project, even though much of it was already available on our project website (now out-of-date). Here I want to describe why I chose the ResearchEquals platform for the complete collection: while many other platforms could also serve to make the project reproducible, choosing ResearchEquals had to do with additional goals.</p> <h2 id="three-additional-goals">Three additional goals…</h2> <p>First, to give credit to other important work of those not involved in the ALL-IN-META-BCG-CORONA project as authors, but indispensable for the trial design and data collection. Second, to make standalone modules that have their own scientific value findable through citations. And third, to highlight the different authorships of the various modules in this project.</p> <p>To achieve these goals I collaborated with ResearchEquals creator Chris Hartgerink to make two step-by-step guides for my collaborators so we would optimally leverage the possibilities of the platform. I’ve attached these guides to the ALL-IN-META-BCG-CORONA collection to share the idea – see the step-by-step guides here on ResearchEquals: (https://www.researchequals.com/modules/wgtb-cagt)[https://www.researchequals.com/modules/wgtb-cagt] – but unfortunately, my goals…</p> <h2 id="-were-not-really-achieved">… were not really achieved</h2> <p>Only the third goal could be partly achieved, but not for a lack of trying. The main problem was that third parties did not integrate the citation data generated by ResearchEquals. Partly because of that, I failed to motivate other authors to make every protocol and risk-of-bias assessment available, and gave up on fully achieving the three additional goals, described in detail below. Yet I am still happy that I tried this and happy with the result: the Replication Package gives complete supplementary material to reproduce our analysis, and is very nicely presented on the ResearchEquals platform.</p> <p>With this story I hope to highlight to other open science enthusiasts that these goals are still worth pursuing, but a lot more difficult than I thought.</p> <h2 id="additional-goal-1-give-credit-to-important-other-work">Additional goal 1: Give credit to important other work</h2> <p>ResearchEquals generates structured citation data that I tried to use to give credit to other important work. The Statistical Analysis Plan of the project, for example, is heavily inspired by the protocol publication of the first clinical trial (the NL one), with many researchers involved that were not authors of our project. By using ResearchEquals I could not only give our Statistical Analysis Plan a DOI and make it available, but also add a citation to the NL protocol. Other platforms to make such documents available, like <a href="https://osf.io/">OSF</a>, do not allow to add a citation in the same way, but only in a reference section within a pdf. References within a pdf on a platform like OSF are not found by any citation data platform, not even by Google Scholar or Scopus Preprint search.</p> <p>Giving credit to all the researchers involved in the trials was important because of the logistics of a prospective meta-analysis that allowed only two authors per trial: a Principle Investigator and a Data Uploader. By generating additional citations to their protocols and motivating them to also publish their data such that I could cite it, I intended to give credit to all important researchers involved in generating the data for the meta-analysis. However, motivating others to generate DOIs for their protocols and data takes time. The flexibility of the ResearchEquals collection would allow us to generate citations of new DOIs also after the paper was published (when the publication itself could not cite this supplementary material anymore), by adding supplementary documents to the collection that could generate new citations.</p> <h2 id="additional-goal-2-make-standalone-modules-findable">Additional goal 2: Make ‘standalone’ modules findable</h2> <p>In a prospective meta-analysis, decisions on study inclusion are made with no trial results available. So risk-of-bias assessments were performed based on the protocols of the participating randomized controlled trials.</p> <p>Some of these protocols were published (NL, DK, BR) and so their DOIs could be added to the collection. ResearchEquals makes them findable as supplementary material to our project, but because they are published in journals, they are already easily findable trough scholarly data platforms like Google Scholar or PubMed. The risk-of-bias assessments of these trial protocols therefore also have standalone scientific value to anyone that comes across these protocols outside of our supplementary material. The way to lead a reader of these protocol publications to the risk-of-bias assessments would be the ‘Cited by’ functionality on a journal website or within a scholarly data platform.</p> <p>ResearchEquals assigns a DOI to our risk-of-bias assessments, and generates citation data for crossref. You can see in this example risk-of-bias assessment of the BR trial protocol that it cites the protocol publication: https://www.researchequals.com/modules/r30w-ksmt. However, these citations are currently not available anywhere other than ResearchEquals itself.</p> <h2 id="third-party-failures">Third-party failures</h2> <p>There was a point at which these citations were findable through Scopus. But Scopus was the only one, and instead of this situation improving over time, it became worse since also Scopus does not display ResearchEquals citations anymore. For example, the citation by the risk-of-bias assessment of the BR trial publication (link above) is not findable through the ‘Cited by’ functionality in any of the six mode widely used ones:</p> <p><a href="https://link.springer.com/article/10.1186/s13063-020-04822-0/metrics">Publisher’s (BMC/Springer Nature) Metrics page of the Trials protocol publication</a></p> <p><a href="https://pubmed.ncbi.nlm.nih.gov/?linkname=pubmed_pubmed_citedin&amp;from_uid=33106170">PubMed ‘Cited By’ section</a></p> <p><a href="https://europepmc.org/search?query=CITES%3A33106170_MED&amp;page=1&amp;sortby=Date%20DESC&amp;sortBy=FIRST_PDATE_D%2Bdesc">Europe PMC ‘Cited By’ section</a></p> <p><a href="https://www.webofscience.com/wos/woscc/summary/a1a3d5b7-cd3d-408d-88d4-bb2cd0b0079f-0160cc294c/date-descending/1">Web of Science ‘Cited By’ section</a></p> <p><a href="https://www.scopus.com/results/results.uri?sort=plf-f&amp;src=s&amp;imp=t&amp;sid=7c2af6f7c8a504b4d0388e99db25e209&amp;sot=cite&amp;sdt=a&amp;sl=23&amp;s=REF%282-s2.0-85093834446%29&amp;origin=recordpage&amp;editSaveSearch=&amp;txGid=06317716e149918349ef2fcc586888ef&amp;sessionSearchId=7c2af6f7c8a504b4d0388e99db25e209&amp;limit=10">Scopus ‘Cited By’ section</a></p> <p><a href="https://scholar.google.com/scholar?cluster=18284083333054586888&amp;hl=nl&amp;as_sdt=0,5">Google Scholar ‘Cited By’ section</a></p> <p>Google Scholar and the Scopus Preprints-‘Cited by’ functionality (in Beta version) do find the citation of the protocol by the MedRxiv preprint. So in that way, I partly achieved to give credit to the three published protocols. But these citations can only indirectly lead a reader to the risk-of-bias assessments of these protocols via the MedRxiv preprint that cites the Replication Package, and therefore do not highlight those as standalone modules with scientific value.</p> <p>For protocols that we intended to make available after the preprint publications the process turned out to be completely ineffective to highlight their risk-of-bias assessments: citations from ResearchEquals would not be findable, so it was ineffective to give credit to the protocol authors (Additional goal 1) as well as lead readers of the protocol to the risk-of-bias assessment (Additional goal 2). This was demotivating, and the interdependencies between the modules made the process of achieving anything with ResearchEquals citations very time-consuming (see below: Interdependencies and waiting).</p> <h2 id="additional-goal-3-highlighting-authorship-of-modules">Additional goal 3: Highlighting authorship of modules</h2> <p>Not all authors were involved in all parts of the project. For example, an external team performed the risk-of-bias assessments that was not involved in any trial, but worked with a representative of Cochrane Netherlands. By making their risk-of-bias assessments available as modules in ResearchEquals, I could show who the authors were and directly connect these modules to their research output by feeding into their ORCID profiles.</p> <p>However, given that I am myself author of many of these modules, I know that they can easily clutter your ORCID profile. I decided to hide most of them from my public profile, and also informed the other authors that they could do that in the step-by-step guide. Of course, this makes the effort to align authorship with modules less effective. Maybe if the reward structures change, showing this type of research output will be beneficial for researchers in the future and this feeling of ‘cluttering’ your profile will cease to exist. I am proud of the Code to reproduce the analysis and figures, and happy of the automatic feeding into my ORCID profile: <a href="https://orcid.org/0000-0002-2147-5510">https://orcid.org/0000-0002-2147-5510</a> But unfortunately, the automatic process classifies it as a ‘Book chapter’ and also does not communicate with Scopus, such that it does not automatically appear on the Pure profile my employer wants me to use: <a href="https://amsterdamumc.org/en/research/researchers/judith-ter-schure-1.htm">https://amsterdamumc.org/en/research/researchers/judith-ter-schure-1.htm</a></p> <h2 id="interdependencies-and-waiting">Interdependencies and waiting…</h2> <p>To achieve all the goals I had on the ResearchEquals platform, I had to motivate others to create profiles and make sure references were added correctly because you can only publish a module once. This introduced a lot of dependencies between the modules and only one order in which they could be published and linked together by citations. Authors had to wait for others to publish modules so very little was published…</p> <p>The major complicating factor was that trial protocols are often amended, so the latest version that was assessed for risk-of-bias might not be the same version that was published. For a fair representation of the process that led to the risk-of-bias assessment I implemented a check on the version our risk-of-bias team received whether that was the same protocol that was published, and if not, ask the clinical trial researchers to explain in a few sentences what the changes were and add that to the risk-of-bias module on ResearchEquals. Hence this process had many steps and many people involved to do well: First, ask the research team whether their protocol is published, and if it is not, whether they want to post it as a module on Research Equals under their own authorship. Wait for them to do that. Second, ask them whether that version of the protocol is the one that was assessed for risk-of-bias and if not, provide detail. Third, ask the risk-of-bias team to wait for this input before posting their assessment on Research Equals such that the citation of the protocol has sufficient context.</p> <h2 id="giving-up">Giving up</h2> <p>This entire scheme turned out to require a large amount of reminders to motivate the other authors, even with a step-by-step guide available. See the step-by-step guides here on ResearchEquals: <a href="https://www.researchequals.com/modules/wgtb-cagt">https://www.researchequals.com/modules/wgtb-cagt</a></p> <p>So it culminated in only one available risk-of-bias assessment of a published protocol that was exactly the same as the one assessed: the BR protocol. This research team of the BR (Brazilian) trial did actually appreciate the citation of their protocol that, thanks to the ResearchEquals platform, was fed into Crossref at the time. But, as we saw above, this citation is not findable anymore.</p> <p>Unfortunately, the trial teams without protocol publications were not immediately posting their protocols on ResearchEquals, because they were still considering publishing them in a journal. Therefore, the risk-of-bias team had to wait posting the risk-of-bias assessments, to make sure these could cite the protocols. And the waiting resulted in postponing, which resulted in giving up.</p> <p>The lack of impact of these citations made me realize that in terms of completeness, probably no-one would bother to ever look at these risk-of-bias analyses as they were not findable as standalone modules. So they might not be worth all this effort.</p> <p>With one risk-of-bias assessment available in the Replicabilion package, the replication package already transparently showed how these assessments were carried out. So I decided to stop bothering everyone. For their credit: the risk-of-bias team did allow me to add all the assessments on ResearchEquals (even if to do it quick, it would be under my authorship), but I did not want to do that without also making the protocols available that were not mine.</p> <h2 id="what-is-there">What is there</h2> <p>All the stuff you would expect in a replication package, like (summary) data, code, figures, Statistical Analysis Plan, instructions for data processing and upload etc, even the Newsletters that were sent during the pandemic. Published NL trial protocol Published DK trial protocol Published BR trial protocol BR trial protocol riskof-bias assessment</p> <h2 id="what-is-still-missing">What is still missing</h2> <p>NL trial protocol riskof-bias assessment DK trial protocol riskof-bias assessment SA trial protocol SA trial protocol riskof-bias assessment US trial protocol US trial protocol riskof-bias assessment HU trial protocol HU trial protocol riskof-bias assessment AF trial protocol AF trial protocol riskof-bias assessment</p> <h2 id="why-i-am-happy-anyway">Why I am happy anyway</h2> <p>As a replication package, I am happy with what is available on ResearchEquals. It is unfortunate that on the collection page, mostly my name as the ‘editor’ of the collection is visible and not the authors of the modules. Bu you can find their names by clicking and accessing the modules individually. The collection functionality puts everything nicely together and has its own DOI, which we linked in the MedRxiv preprint. In that way it was (and is) still possible to update this supplementary material. This is a functionality that we used extensively by filling most of the collection after the MedRxiv publication.</p> <p>Even though I did not manage to meet most of my three additional goals above, I’m still happy that I tried. These goals are valuable enough to spend the time. But you can probably guess my level of frustration at some point. Now, that frustration is a long time ago and I feel that the effort might serve a purpose in the future. But of course, for that to even be possible, I have to openly share the story. So here it is.</p>]]></content><author><name></name></author><category term="Scientists"/><summary type="html"><![CDATA[How I did the best I could and spent a large amount of time, still gave up before fully completing it, am happy I tried it, happy I gave up, and happy with the result. ResearchEquals is a research publishing platform that is used by open science enthusiasts like myself. This blog post is...]]></summary></entry><entry><title type="html">[Peers] E-values have a wikipedia page</title><link href="https://judithterschure.github.io/blog/Peers__E-values_have_a_wikipedia_page" rel="alternate" type="text/html" title="[Peers] E-values have a wikipedia page"/><published>2024-03-06T00:00:00+00:00</published><updated>2024-03-06T00:00:00+00:00</updated><id>https://judithterschure.github.io/blog/Peers__E-values_have_a_wikipedia_page</id><content type="html" xml:base="https://judithterschure.github.io/blog/Peers__E-values_have_a_wikipedia_page"><![CDATA[<p><img src="/assets/img/posts/Peers__E-values_have_a_wikipedia_page-0.jpg" alt=""/></p> <p>The research field I work in, that of anytime-valid statistics and e-values, now has a Wikipedia page!</p> <p><a href="https://en.wikipedia.org/wiki/E-values">https://en.wikipedia.org/wiki/E-values</a></p> <p>(Image: Hypothetical e-values reported in the Ter Schure et al. (2022) MedRxiv publication also referenced on the Wikipedia page: ter Schure, J. A., Ly, A., Belin, L., Benn, C. S., Bonten, M. J., Cirillo, J. D., … &amp; van Werkhoven, C. H. (2022). Bacillus Calmette-Guérin vaccine to reduce COVID-19 infections and hospitalisations in healthcare workers–a living systematic review and prospective ALL-IN meta-analysis of individual participant data from randomised controlled trials. medRxiv, 2022-12. https://doi.org/10.1101/2022.12.15.22283474.)</p>]]></content><author><name></name></author><category term="Peers"/><summary type="html"><![CDATA[The research field I work in, that of anytime-valid statistics and e-values, now has a Wikipedia page! [https://en.wikipedia.org/wiki/E-values](https://en.wikipedia.org/wiki/E-values)]]></summary></entry><entry><title type="html">[Scientists] Avoidable research waste caused by data transfer agreements</title><link href="https://judithterschure.github.io/blog/Scientists__Avoidable_research_waste_caused_by_data_transfer_agreements" rel="alternate" type="text/html" title="[Scientists] Avoidable research waste caused by data transfer agreements"/><published>2023-07-04T00:00:00+00:00</published><updated>2023-07-04T00:00:00+00:00</updated><id>https://judithterschure.github.io/blog/Scientists__Avoidable_research_waste_caused_by_data_transfer_agreements</id><content type="html" xml:base="https://judithterschure.github.io/blog/Scientists__Avoidable_research_waste_caused_by_data_transfer_agreements"><![CDATA[<p><img src="/assets/img/posts/Scientists__Avoidable_research_waste_caused_by_data_transfer_agreements-0.jpg" alt=""/></p> <p>Early summer of 2020, eight trials agreed to collaborate in a prospective meta-analysis and keep a live account of the pooled results. Each was interested in the question whether the BCG vaccine, originally developed to protect against tuberculosis, had a nonspecific immune effect against the SarS-Cov-2 virus. Could such an effect be observed in a reduction of the risk of COVID-19 infection or hospitalization? One by one, they started trials in healthcare workers to investigate this hypothesis: the Netherlands (NL in the plot), South Africa (SA in the plot), the United States, Denmark, Hungary, France, Brazil and Guinea-Bissau/Mozambique (AF, in the plot)).</p> <p>In December 2022 we made the first results of our live analysis available on MedRxiv (see <a href="https://www.medrxiv.org/content/10.1101/2022.12.15.22283474v1.full.pdf+html">here</a>). The figure above simplifies the results for infections as they developed over time – it includes the three trials contributing most data. (All trials together convey the same message in Figure 7 of the preprint but clutter the plot; not simplifying interpretation.)</p> <h2 id="getting-started">Getting started</h2> <p>The first trial was ready for data upload in June 2020. We were very excited about monitoring the results in a dashboard. I blogged about that <a href="/blog/2020/Personal__COVID-19_trial_dashboard/">here</a>. We designed this meta-analysis such that it could detect a beneficial effect of the BCG vaccine as soon as possible and inform other trials that were still in preparation.</p> <p>We did not really design it to detect futility as soon as possible. What if we had?</p> <h2 id="the-data">The data</h2> <p>The plot above shows at the bottom that the first two trials already observed many events of COVID-19 infection in the early Spring of 2020 (NL), summer of 2020 (SA) and the Fall of 2020 (NL). We can even recognize the lockdown in the Spring of 2020 in the Netherlands, which introduced a gap in the observed infections, with the next pandemic wave starting right at the end of the summer.</p> <p>These events of infection are observed in healthcare workers that were randomly assigned to either the BCG vaccine or a control vaccine, to investigate their risk of COVID-19 infection (and hospitalization). When more of these events of infection are observed in the group of healthcare workers that received the control vaccine, we estimate that the group that received the BCG vaccine is protected by the vaccine – with a hazard ratio smaller than 1 (risk in the vaccine group being smaller) and a Vaccine Efficacy (VE) that is larger than 0%. When more of these events of infection are observed in the group that received BCG, it is the other way around, and we estimate that the BCG vaccine does not protect and can even increase the risk of infection – with a hazard ratio larger than 1.</p> <h2 id="reaching-conclusions-in-january-2021">Reaching conclusions in January 2021…?</h2> <p>If we had decided to monitor for futiliy, a good candidate threshold would have been the 30% minimum Vaccine Efficacy (VE) set by the FDA in June 2020 in their <a href="https://www.fda.gov/media/139638/download">published guidance</a> for COVID-19 vaccines trials.</p> <p>The plot above shows that the final months of 2020 we could have seen it coming that the BCG trials were futile according to this 30% threshold. The typical effect of the BCG vaccine was less impressive than 30%. By January 2021, also all values in its 95%-confidence interval were less impressive than 30%.</p> <p>Studying this specific question further could be considered research waste. If we had seen this conclusion coming in the Fall of 2020, the planned trial in Guinea-Bissau/Mozambique (AF, in the plot) might have been able to change course.</p> <h2 id="but-not-having-the-data">….but not having the data</h2> <p>Except that we could not have seen that coming in 2020. Even for the first trials that were ready for data upload in June of 2020, it took until July 2021 before there was a legal agreement for data sharing – a data transfer agreement (DTA). There are trials for which this took until January 2023 that are not even in the MedRxiv publication yet.</p> <p>Hence, DTAs are causing avoidable research waste. In my future research, I hope to contribute to statistical methods that can spur collaboration in prospective meta-analysis – without DTAs.</p>]]></content><author><name></name></author><category term="Scientists"/><summary type="html"><![CDATA[Early summer of 2020, eight trials agreed to collaborate in a prospective meta-analysis and keep a live account of the pooled results. Each was interested in the question whether the BCG vaccine, originally develop...]]></summary></entry><entry><title type="html">[Peers] Dataviz matters! Update to my Ph.D. thesis</title><link href="https://judithterschure.github.io/blog/Peers__Dataviz_matters!_Update_to_my_Ph_D_thesis" rel="alternate" type="text/html" title="[Peers] Dataviz matters! Update to my Ph.D. thesis"/><published>2023-01-20T00:00:00+00:00</published><updated>2023-01-20T00:00:00+00:00</updated><id>https://judithterschure.github.io/blog/Peers__Dataviz_matters!_Update_to_my_Ph_D_thesis</id><content type="html" xml:base="https://judithterschure.github.io/blog/Peers__Dataviz_matters!_Update_to_my_Ph_D_thesis"><![CDATA[<p><img src="/assets/img/posts/Peers__Dataviz_matters_Update_to_my_Ph_D_thesis-0.png" alt=""/> Nicos Starreveld writes a fantastic series of articles in the member’s magazine of the KWG (‘Koninklijk Wiskundig Genootschap’, Royal Dutch Mathematical Society). He reads recent Ph.D. theses with great care and interviews Ph.D. candidates in mathematics that are preparing for their defense. The series is called ‘In Defense’/’In de Verdediging’ and appears (mostly) in English. This is an article that discusses the work of my current colleague dr. Birgit Sollie and this is an article in the series on the work of my former colleague dr. Yfke Dulek. I especially like the description of mathematical work as tirelessly exploring how something can be done, resulting in constructing an impossibily proof that also makes you happy.</p> <p>I was very honored for my Ph.D. thesis to be featured in the piece that appeared in December. You can read it here. It provides a great summary of the main themes of my Ph.D. thesis: research waste, accumulation bias, and of course: ALL-IN meta-analysis</p>]]></content><author><name></name></author><category term="Peers"/><summary type="html"><![CDATA[The final question at my Ph.D. defense was by prof. Richard Gill. He saw an easy improvement to the data visualization in the introduction of my Ph.D. thesis. Not that I was too happy about it myself. The main point of the figures was that sampling distributions and p-values depend a lot on the sample size (the number of heart attacks n, in the example) – you can only visualize them in this way given a sample size or stopping rule. That was still clear from the figure, but it was very distracting and counterintuitive that the distributions in the figure shrank, for which I had to add a long caption below Figure 1 of my Ph.D. thesis. It was October 2021, and I had set the deadline for my Ph.D. thesis to November 1st. I simply did not see the easy fix. Thanks to Richard, my Ph.D. now has better figures. Also thanks to Nicos Starreveld, who wrote a very nice article about my Ph.D. thesis that reuses the improved figure. The updated Ph.D. thesis can be found in the Amsterdam UMC repository. In this blogpost I also post the improvements to Figure 2 and Figure 3 that follow.]]></summary></entry><entry><title type="html">[General] Great summary article about my Ph.D. thesis</title><link href="https://judithterschure.github.io/blog/General__Great_summary_article_about_my_Ph.D._thesis" rel="alternate" type="text/html" title="[General] Great summary article about my Ph.D. thesis"/><published>2023-01-19T00:00:00+00:00</published><updated>2023-01-19T00:00:00+00:00</updated><id>https://judithterschure.github.io/blog/General__Great_summary_article_about_my_Ph.D._thesis</id><content type="html" xml:base="https://judithterschure.github.io/blog/General__Great_summary_article_about_my_Ph.D._thesis"><![CDATA[<p><img src="/assets/img/posts/General__Great_summary_article_about_my_Ph.D._thesis-0.png" alt=""/></p> <p>Nicos Starreveld writes a fantastic series of articles in the member’s magazine of the KWG (‘Koninklijk Wiskundig Genootschap’, Royal Dutch Mathematical Society). He reads recent Ph.D. theses with great care and interviews Ph.D. candidates in mathematics that are preparing for their defense. The series is called ‘In Defense’/’In de Verdediging’ and appears (mostly) in English. <a href="https://www.nieuwarchief.nl/serie5/pdf/naw5-2021-22-3-192.pdf">This</a> is an article that discusses the work of my current colleague dr. Birgit Sollie and <a href="https://www.nieuwarchief.nl/serie5/pdf/naw5-2021-22-4-255.pdf">this</a> is an article in the series on the work of my former colleague dr. Yfke Dulek. I especially like the description of mathematical work as tirelessly exploring how something can be done, resulting in constructing an impossibily proof that also makes you happy.</p> <p>I was very honored for my Ph.D. thesis to be featured in the piece that appeared in December. You can read it <a href="https://www.nieuwarchief.nl/serie5/pdf/naw5-2022-23-4-246.pdf">here</a>. It provides a great summary of the main themes of my Ph.D. thesis: research waste, accumulation bias, and of course: ALL-IN meta-analysis</p> <p>Thu, 19 January</p>]]></content><author><name></name></author><category term="General"/><summary type="html"><![CDATA[Nicos Starreveld writes a fantastic series of articles in the member's magazine of the KWG ('Koninklijk Wiskundig Genootschap', Royal Dutch Mathematical Society). He reads recent Ph.D. theses with great care and interviews Ph.D. candidates in mathematics that are preparing for their defense. The series is called 'In Defense'/'In de Verdediging' and appears (mostly) in English. This is an article that discusses the work of my current colleague dr. Birgit Sollie and this is an article in the series on the work of my former colleague dr. Yfke Dulek. I especially like the description of mathematical work as tirelessly exploring how something can be done, resulting in constructing an impossibily proof that also makes you happy.I was very honored for my Ph.D. thesis to be featured in the piece that appeared in December. You can read it here. It provides a great summary of the main themes of my Ph.D. thesis: research waste, accumulation bias, and of course: ALL-IN meta-analysis]]></summary></entry><entry><title type="html">[General] Infographic!</title><link href="https://judithterschure.github.io/blog/General__Infographic_" rel="alternate" type="text/html" title="[General] Infographic!"/><published>2023-01-19T00:00:00+00:00</published><updated>2023-01-19T00:00:00+00:00</updated><id>https://judithterschure.github.io/blog/General__Infographic_</id><content type="html" xml:base="https://judithterschure.github.io/blog/General__Infographic_"><![CDATA[<p><img src="/assets/img/posts/General__Infographic_-0.png" alt=""/></p> <p>Het is echt een hardnekkig fabeltje. Zelfs tijdens een sessie over lawines beweerde een spreker uit een Alpenland: “Jullie lopen meer risico op de <em>autobahn</em> naar de bergen toe, dan in de sneeuw daar!”</p> <p>Hoe gevaarlijk is skitoeren nu echt als je het vergelijkt met autorijden? <a href="http://het is echt een hardnekkig fabeltje. Zelfs tijdens een sessie over lawines beweerde een spreker uit een Alpenland: “Jullie lopen meer risico op de autobahn naar de bergen toe, dan in de sneeuw daar!” Hoe gevaarlijk is skitoeren nu echt als je het vergelijkt met autorijden?Op_de_VVSOR_blog_publiceerde_ik_een_infographic_die_dat_uitlegt_=">Op de VVSOR blog publiceerde ik een infographic die dat uitlegt</a>.</p> <p>Thu, 19 January</p>]]></content><author><name></name></author><category term="General"/><summary type="html"><![CDATA[Het is echt een hardnekkig fabeltje. Zelfs tijdens een sessie over lawines beweerde een spreker uit een Alpenland: “Jullie lopen meer risico op de autobahn naar de bergen toe, dan in de sneeuw daar!”Hoe gevaarlijk is skitoeren nu echt als je het vergelijkt met autorijden? Op de VVSOR blog publiceerde ik een infographic die dat uitlegt.]]></summary></entry><entry><title type="html">[Peers] Best Oral Presentation: Evidence-Based Research</title><link href="https://judithterschure.github.io/blog/Peers__Best_Oral_Presentation__Evidence-Based_Research" rel="alternate" type="text/html" title="[Peers] Best Oral Presentation: Evidence-Based Research"/><published>2022-10-07T00:00:00+00:00</published><updated>2022-10-07T00:00:00+00:00</updated><id>https://judithterschure.github.io/blog/Peers__Best_Oral_Presentation__Evidence-Based_Research</id><content type="html" xml:base="https://judithterschure.github.io/blog/Peers__Best_Oral_Presentation__Evidence-Based_Research"><![CDATA[<p><img src="/assets/img/posts/Peers__Best_Oral_Presentation__Evidence-Based_Research-0.png" alt=""/></p> <p>I received an award for a talk!</p> <p>The goals of EBR – or evbres: Evidence-Based Research – have been central to the work in my Ph.D. thesis on ALL-IN meta-analysis. During the EBR conference I argued that these new statistical methods could be the future of EBR, and received a Best Oral Presentation award for it. (<a href="https://twitter.com/evbres/status/1578415259466928129">Here’s the Twitter announcement.</a>)</p> <p>The great thing about online conferences is that you can still watch the presentation on <a href="https://www.youtube.com/playlist?list=PLkIyhRK9IXIPiFluG5yFRpGV06PwYu4LD">the EBR conference’ Youtube channel</a>.</p> <p>Read more about Evidence-Based Research on <a href="https://evbres.eu/about/about-evbres/">the EVBRES website</a>.</p> <p>Fri, 07 October</p>]]></content><author><name></name></author><category term="Peers"/><summary type="html"><![CDATA[I received an award for a talk!The goals of EBR – or evbres: Evidence-Based Research – have been central to the work in my Ph.D. thesis on ALL-IN meta-analysis. During the EBR conference I argued that these new statistical methods could be the future of EBR, and received a Best Oral Presentation award for it. (Here's the Twitter announcement.)The great thing about online conferences is that you can still watch the presentation on the EBR conference' Youtube channel.Read more about Evidence-Based Research on the EVBRES website.]]></summary></entry><entry><title type="html">[General] Defense, title and signature!</title><link href="https://judithterschure.github.io/blog/General__Defense__title_and_signature_" rel="alternate" type="text/html" title="[General] Defense, title and signature!"/><published>2022-04-11T00:00:00+00:00</published><updated>2022-04-11T00:00:00+00:00</updated><id>https://judithterschure.github.io/blog/General__Defense__title_and_signature_</id><content type="html" xml:base="https://judithterschure.github.io/blog/General__Defense__title_and_signature_"><![CDATA[<p><img src="/assets/img/posts/General__Defense__title_and_signature_-0.png" alt=""/></p> <p>On April 7th 2022, I successfully defended my Ph.D. dissertation, received my “Dr.” title, and signed the famous “Zweetkamertje” of Leiden University!</p> <p>Many were there with me! I want to thank my supervisors Peter Grünwald and Daniel Lakens and the reading committee that evaluated my dissertation: Jelle Goeman, Joanna in ‘t Hout, Glenn Shafer, and Alex Sutton.</p> <p>It was a very inspiring discussion following the questions from the opposition committee: Glenn Shafer, Joanna in ‘t Hout, Henri van Werkhoven, Jelle Goeman, Hein Putter, and Richard Gill.</p> <p>Everything went super smooth, thanks to my wonderful paranimfs Laura Schut and Marnick van de Zande. I really couldn’t have done it without them!</p> <p>And I want to thank my family, friends, colleagues, and CWI for their support. This was a truly great day!</p> <p>A news article about my defense can be found on the <a href="https://www.universiteitleiden.nl/nieuws/2022/04/nieuwe-statistiek-brengt-studies-in-vroeg-stadium-samen">Leiden University website</a> (in Dutch) and at the <a href="https://www.cwi.nl/news/2022/new-statistical-method-brings-studies-together-at-an-early-stage">CWI website</a> (in English). The complete dissertation can be found in the <a href="https://hdl.handle.net/1887/3281933">Leiden University Repository</a> and the <a href="https://ir.cwi.nl/pub/31587">CWI Repository</a>.</p> <p>I did not want to share photos unasked, but my paranimfs insisted that this diploma photo-op was made for posting:</p> <p><img src="/assets/img/posts/General__Defense__title_and_signature_-1.jpeg" alt=""/></p> <p>Mon, 11 April</p>]]></content><author><name></name></author><category term="General"/><summary type="html"><![CDATA[On April 7th 2022, I successfully defended my Ph.D. dissertation, received my "Dr." title, and signed the famous "Zweetkamertje" of Leiden University!Many were there with me! I want to thank my supervisors Peter Grünwald and Daniel Lakens and the reading committee that evaluated my dissertation: Jelle Goeman, Joanna in 't Hout, Glenn Shafer, and Alex Sutton. It was a very inspiring discussion following the questions from the opposition committee: Glenn Shafer, Joanna in 't Hout, Henri van Werkhoven, Jelle Goeman, Hein Putter, and Richard Gill.Everything went super smooth, thanks to my wonderful paranimfs Laura Schut and Marnick van de Zande. I really couldn't have done it without them!And I want to thank my family, friends, colleagues, and CWI for their support. This was a truly great day! A news article about my defense can be found on the Leiden University website (in Dutch) and on the CWI website (in English). The complete dissertation can be found in the Leiden University Repository and the CWI Repository.I did not want to share photos unasked, but my paranimfs insisted that this diploma photo-op was made for posting:]]></summary></entry><entry><title type="html">[Peers] My propositions!</title><link href="https://judithterschure.github.io/blog/Peers__My_propositions_" rel="alternate" type="text/html" title="[Peers] My propositions!"/><published>2022-03-30T00:00:00+00:00</published><updated>2022-03-30T00:00:00+00:00</updated><id>https://judithterschure.github.io/blog/Peers__My_propositions_</id><content type="html" xml:base="https://judithterschure.github.io/blog/Peers__My_propositions_"><![CDATA[<p><img src="/assets/img/posts/Peers__My_propositions_-0.jpeg" alt=""/></p> <p><em>Photo: <a href="https://www.medewerkers.universiteitleiden.nl/locaties/academiegebouw?cf=wiskunde-en-natuurwetenschappen&amp;cd=mathematisch-instituut-mi#tab-1">Leiden Academiegebouw</a></em></p> <p>Ten propositions, following Leiden tradition, with at least four about my dissertation, four about my field, and at most four personal statements.</p> <p>They do not appear in the Ph.D. dissertation itself: it is custom to add them on a separate sheet in the printed book. So they are easily lost. Here, I try to make them easy to find!</p> <p>Propositions Ph.D. defense</p> <p>Judith ter Schure – ALL-IN meta-analysis</p> <ol> <li>Instead of progressing one publication at a time, with everyone focusing on their own paper, clinical science should be more of a continuous collaborative effort. (This dissertation)</li> <li>ALL-IN meta-analysis can be especially efficient for time-to-event data at interim stages of studies when individual clinical trials are slow in themselves to provide the necessary number of events for completion. (Chapter 1 of this dissertation)</li> <li>Alpha spending forces the researcher into an all-or-nothing decision at the end of a clinical trial, while alpha saving and safe tests prepare the researcher for future trials and focus on contributing to the existing line of research. (Chapter 2 of this dissertation)</li> <li>The decision to replicate only some studies (instead of all of them) biases the sampling distribution of study series but can be a very efficient approach to set priorities in research and reduce research waste. (Chapter 3, 4, and 5 of this dissertation)</li> <li>We need statistical methodology that gives yes/no-answers since without a finish line we cannot know how to complete a line of research and allocate resources in any optimal way. (Field of this dissertation)</li> <li>Collaboration and data sharing in meta-analyses decrease the risk of mistakes due to honest errors and questionable research practices, and prevent that we must otherwise assume the worst (i.e. according to Richard Smith, in his BMJ blog of July 5th, 2021 “that health research is fraudulent until proven otherwise”). (Field of this dissertation)</li> <li>The Covid-19 pandemic has shown that it is not always better to resort to big data and complicated analysis, but that we should more often return to the principles of the 1980s (e.g. those of Richard Peto) and rely on randomized controlled trials that are simple and large. (Field of this dissertation)</li> <li>“Why Most Clinical Research Is Not Useful” was a much better paper title than “Why Most Published Research Findings Are False”. (Field of this dissertation)</li> <li>If we do not have enough time as researchers to read papers, review papers and help each other write good papers, then we need to write fewer papers, ask for fewer papers per Ph.D. dissertation and create fewer Ph.D. positions. (Personal)</li> <li>The martingale – the mathematical process that drives ALL-IN meta-analysis – has a strange name that might not have arisen among the villagers that behave martigale, i.e. in the way of Martigues, since “Martingales have nothing to see with Martigues, have nothing to see with Martigues, have nothing to see with Martigues” – gentleman from the Martigues historical museum (Musée d’histoire de Martigues) on November 13th, 2021. (Personal)</li> </ol> <p>Wed, 30 March</p>]]></content><author><name></name></author><category term="Peers"/><summary type="html"><![CDATA[Ten propositions, following Leiden tradition, with at least four about my dissertation, four about my field and at most four personal statements. They do not appear in the Ph.D. dissertation itself: it is custom to add them on a separate sheet in the printed book. So they are easily lost. Here, I try to make them easy to find!]]></summary></entry></feed>